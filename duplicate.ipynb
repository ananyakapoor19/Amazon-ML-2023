{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae96ad9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import seaborn as sns\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "319b99cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"stem_df_duplicate.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04220ee1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRODUCT_ID</th>\n",
       "      <th>TITLE</th>\n",
       "      <th>BULLET_POINTS</th>\n",
       "      <th>DESCRIPTION</th>\n",
       "      <th>PRODUCT_TYPE_ID</th>\n",
       "      <th>PRODUCT_LENGTH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2765088</td>\n",
       "      <td>['priknik', 'horn', 'red', 'electr', 'air', 'h...</td>\n",
       "      <td>['loud', 'dual', 'tone', 'trumpet', 'horn', 'c...</td>\n",
       "      <td>['specif', 'color', 'red', 'materi', 'aluminiu...</td>\n",
       "      <td>6411</td>\n",
       "      <td>6.617445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1594019</td>\n",
       "      <td>['alishah', 'women', 'cotton', 'ankl', 'length...</td>\n",
       "      <td>['made', 'cotton', 'lycra', 'give', 'way', 'st...</td>\n",
       "      <td>['aishah', 'women', 'lycra', 'cotton', 'ankel'...</td>\n",
       "      <td>2663</td>\n",
       "      <td>6.668738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2152929</td>\n",
       "      <td>['hin', 'metal', 'bucket', 'shape', 'plant', '...</td>\n",
       "      <td>['simpl', 'eleg', 'great', 'display', 'indoor'...</td>\n",
       "      <td>['hin', 'bring', 'eleg', 'look', 'pot', 'stand...</td>\n",
       "      <td>5027</td>\n",
       "      <td>6.856462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2026580</td>\n",
       "      <td>['delavala', 'self', 'adhes', 'kitchen', 'back...</td>\n",
       "      <td>['high', 'qualiti', 'pvc', 'materi', 'kitchen'...</td>\n",
       "      <td>['pstrongaluminum', 'foil', 'stickersgood', 'k...</td>\n",
       "      <td>5269</td>\n",
       "      <td>6.891882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2998633</td>\n",
       "      <td>['hexwel', 'essenti', 'oil', 'home', 'fragranc...</td>\n",
       "      <td>['pure', 'natur', 'essenti', 'oil', 'fragranc'...</td>\n",
       "      <td>['transform', 'home', 'workplac', 'hotel', 'ro...</td>\n",
       "      <td>6982</td>\n",
       "      <td>5.975591</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PRODUCT_ID                                              TITLE  \\\n",
       "0     2765088  ['priknik', 'horn', 'red', 'electr', 'air', 'h...   \n",
       "1     1594019  ['alishah', 'women', 'cotton', 'ankl', 'length...   \n",
       "2     2152929  ['hin', 'metal', 'bucket', 'shape', 'plant', '...   \n",
       "3     2026580  ['delavala', 'self', 'adhes', 'kitchen', 'back...   \n",
       "4     2998633  ['hexwel', 'essenti', 'oil', 'home', 'fragranc...   \n",
       "\n",
       "                                       BULLET_POINTS  \\\n",
       "0  ['loud', 'dual', 'tone', 'trumpet', 'horn', 'c...   \n",
       "1  ['made', 'cotton', 'lycra', 'give', 'way', 'st...   \n",
       "2  ['simpl', 'eleg', 'great', 'display', 'indoor'...   \n",
       "3  ['high', 'qualiti', 'pvc', 'materi', 'kitchen'...   \n",
       "4  ['pure', 'natur', 'essenti', 'oil', 'fragranc'...   \n",
       "\n",
       "                                         DESCRIPTION  PRODUCT_TYPE_ID  \\\n",
       "0  ['specif', 'color', 'red', 'materi', 'aluminiu...             6411   \n",
       "1  ['aishah', 'women', 'lycra', 'cotton', 'ankel'...             2663   \n",
       "2  ['hin', 'bring', 'eleg', 'look', 'pot', 'stand...             5027   \n",
       "3  ['pstrongaluminum', 'foil', 'stickersgood', 'k...             5269   \n",
       "4  ['transform', 'home', 'workplac', 'hotel', 'ro...             6982   \n",
       "\n",
       "   PRODUCT_LENGTH  \n",
       "0        6.617445  \n",
       "1        6.668738  \n",
       "2        6.856462  \n",
       "3        6.891882  \n",
       "4        5.975591  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a19700f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(988783, 10000)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=10000)\n",
    "\n",
    "# concatenate the three text columns into a single text column\n",
    "df['concat_text'] = df['DESCRIPTION'] + ' ' + df['TITLE'] + ' ' + df['BULLET_POINTS']\n",
    "\n",
    "# vectorize the concatenated text column\n",
    "X1 = vectorizer.fit_transform(df['concat_text'])\n",
    "\n",
    "# print the shape of the resulting feature matrix\n",
    "print(X1.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5866f466",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "# Perform dimensionality reduction on the sparse matrix\n",
    "svd = TruncatedSVD(n_components=100)\n",
    "X_svd = svd.fit_transform(X1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7bcde072",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['PRODUCT_LENGTH']\n",
    "X = np.concatenate([X_svd, df['PRODUCT_TYPE_ID'].values.reshape(-1,1)], axis=1)\n",
    "# XX1 = np.concatenate([X_svd.toarray(), df['PRODUCT_TYPE_ID'].values.reshape(-1,1)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36dc0049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.7552036585131559\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# train a linear regression model\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "# make predictions on the test set\n",
    "y_pred = lr_model.predict(X_test)\n",
    "# calculate the mean squared error (MSE) of the predictions\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab0c4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "score = max( 0 , 100*(mean_absolute_percentage_error(y_test, y_pred)/100000000000000))\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9096a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# initialize and train a classifier\n",
    "clf = RandomForestRegressor()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# predict on test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# evaluate the model\n",
    "print(\"MAE:\", mean_absolute_error(y_test, y_pred))\n",
    "print(\"MSE:\", mean_squared_error(y_test, y_pred))\n",
    "print(\"R2 score:\", r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08df1feb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53add8fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45202ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab2e943",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# initialize and train a classifier\n",
    "clf = RandomForestRegressor()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# predict on test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# evaluate the model\n",
    "print(\"MAE:\", mean_absolute_error(y_test, y_pred))\n",
    "print(\"MSE:\", mean_squared_error(y_test, y_pred))\n",
    "print(\"R2 score:\", r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d14125d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935b1aba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead9857e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08614cc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db88cd68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df101be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8afd9dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d377e440",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "70a8d12b",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[1;32mIn [58]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m vectorizer \u001b[38;5;241m=\u001b[39m HashingVectorizer(n_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10000\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# concatenate the three text columns into a single text column\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconcat_text\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDESCRIPTION\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTITLE\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBULLET_POINTS\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# vectorize the concatenated text column\u001b[39;00m\n\u001b[0;32m     10\u001b[0m tfidf \u001b[38;5;241m=\u001b[39m vectorizer\u001b[38;5;241m.\u001b[39mtransform(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconcat_text\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\ops\\common.py:72\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[0;32m     70\u001b[0m other \u001b[38;5;241m=\u001b[39m item_from_zerodim(other)\n\u001b[1;32m---> 72\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\arraylike.py:102\u001b[0m, in \u001b[0;36mOpsMixin.__add__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__add__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__add__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[1;32m--> 102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_arith_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py:6259\u001b[0m, in \u001b[0;36mSeries._arith_method\u001b[1;34m(self, other, op)\u001b[0m\n\u001b[0;32m   6257\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_arith_method\u001b[39m(\u001b[38;5;28mself\u001b[39m, other, op):\n\u001b[0;32m   6258\u001b[0m     \u001b[38;5;28mself\u001b[39m, other \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39malign_method_SERIES(\u001b[38;5;28mself\u001b[39m, other)\n\u001b[1;32m-> 6259\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbase\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mIndexOpsMixin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_arith_method\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\base.py:1325\u001b[0m, in \u001b[0;36mIndexOpsMixin._arith_method\u001b[1;34m(self, other, op)\u001b[0m\n\u001b[0;32m   1322\u001b[0m rvalues \u001b[38;5;241m=\u001b[39m ensure_wrapped_if_datetimelike(rvalues)\n\u001b[0;32m   1324\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(\u001b[38;5;28mall\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 1325\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marithmetic_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1327\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_construct_result(result, name\u001b[38;5;241m=\u001b[39mres_name)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py:226\u001b[0m, in \u001b[0;36marithmetic_op\u001b[1;34m(left, right, op)\u001b[0m\n\u001b[0;32m    222\u001b[0m     _bool_arith_check(op, left, right)\n\u001b[0;32m    224\u001b[0m     \u001b[38;5;66;03m# error: Argument 1 to \"_na_arithmetic_op\" has incompatible type\u001b[39;00m\n\u001b[0;32m    225\u001b[0m     \u001b[38;5;66;03m# \"Union[ExtensionArray, ndarray[Any, Any]]\"; expected \"ndarray[Any, Any]\"\u001b[39;00m\n\u001b[1;32m--> 226\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m \u001b[43m_na_arithmetic_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    228\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res_values\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py:165\u001b[0m, in \u001b[0;36m_na_arithmetic_op\u001b[1;34m(left, right, op, is_cmp)\u001b[0m\n\u001b[0;32m    162\u001b[0m     func \u001b[38;5;241m=\u001b[39m partial(expressions\u001b[38;5;241m.\u001b[39mevaluate, op)\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 165\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    166\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m    167\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_cmp \u001b[38;5;129;01mand\u001b[39;00m (is_object_dtype(left\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mor\u001b[39;00m is_object_dtype(right)):\n\u001b[0;32m    168\u001b[0m         \u001b[38;5;66;03m# For object dtype, fallback to a masked operation (only operating\u001b[39;00m\n\u001b[0;32m    169\u001b[0m         \u001b[38;5;66;03m#  on the non-missing values)\u001b[39;00m\n\u001b[0;32m    170\u001b[0m         \u001b[38;5;66;03m# Don't do this for comparisons, as that will handle complex numbers\u001b[39;00m\n\u001b[0;32m    171\u001b[0m         \u001b[38;5;66;03m#  incorrectly, see GH#32047\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:241\u001b[0m, in \u001b[0;36mevaluate\u001b[1;34m(op, a, b, use_numexpr)\u001b[0m\n\u001b[0;32m    238\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m op_str \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    239\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m use_numexpr:\n\u001b[0;32m    240\u001b[0m         \u001b[38;5;66;03m# error: \"None\" not callable\u001b[39;00m\n\u001b[1;32m--> 241\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m    242\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _evaluate_standard(op, op_str, a, b)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:129\u001b[0m, in \u001b[0;36m_evaluate_numexpr\u001b[1;34m(op, op_str, a, b)\u001b[0m\n\u001b[0;32m    126\u001b[0m     _store_test_result(result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 129\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_evaluate_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:70\u001b[0m, in \u001b[0;36m_evaluate_standard\u001b[1;34m(op, op_str, a, b)\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _TEST_MODE:\n\u001b[0;32m     69\u001b[0m     _store_test_result(\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m---> 70\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "\n",
    "\n",
    "vectorizer = HashingVectorizer(n_features=10000)\n",
    "\n",
    "# concatenate the three text columns into a single text column\n",
    "df['concat_text'] = df['DESCRIPTION'] + ' ' + df['TITLE'] + ' ' + df['BULLET_POINTS']\n",
    "\n",
    "# vectorize the concatenated text column\n",
    "X = vectorizer.transform(df['concat_text'])\n",
    "\n",
    "# print the shape of the resulting feature matrix\n",
    "print(X.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "98e5629f",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 368. GiB for an array with shape (988783, 50000) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[1;32mIn [59]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m y \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPRODUCT_LENGTH\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m----> 2\u001b[0m XX1 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate([\u001b[43mX1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPRODUCT_TYPE_ID\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m)], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\sparse\\compressed.py:1029\u001b[0m, in \u001b[0;36m_cs_matrix.toarray\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m   1027\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m order \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1028\u001b[0m     order \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_swap(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcf\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m-> 1029\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_toarray_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1030\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (out\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mc_contiguous \u001b[38;5;129;01mor\u001b[39;00m out\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mf_contiguous):\n\u001b[0;32m   1031\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOutput array must be C or F contiguous\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\sparse\\base.py:1185\u001b[0m, in \u001b[0;36mspmatrix._process_toarray_args\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m   1183\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n\u001b[0;32m   1184\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1185\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 368. GiB for an array with shape (988783, 50000) and data type float64"
     ]
    }
   ],
   "source": [
    "y = df['PRODUCT_LENGTH']\n",
    "XX1 = np.concatenate([X1.toarray(), df['PRODUCT_TYPE_ID'].values.reshape(-1,1)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21601faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(XX1, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# train a linear regression model\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8f85bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions on the test set\n",
    "y_pred = lr_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d03f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = lr_model.score(X_train,y_train)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d367155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the mean squared error (MSE) of the predictions\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59df7535",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "score = max( 0 , 100*(mean_absolute_percentage_error(y_test, y_pred)/100000000000000))\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c78fab9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(988783, 50000)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=50000)\n",
    "\n",
    "# concatenate the three text columns into a single text column\n",
    "df['concat_text'] = df['DESCRIPTION'] + ' ' + df['TITLE'] + ' ' + df['BULLET_POINTS']\n",
    "\n",
    "# vectorize the concatenated text column\n",
    "X1 = vectorizer.fit_transform(df['concat_text'])\n",
    "\n",
    "# print the shape of the resulting feature matrix\n",
    "print(X1.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f98d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "text_cols = ['DESCRIPTION', 'TITLE', 'BULLET_POINTS']\n",
    "num_cols = ['PRODUCT_TYPE_ID', 'PRODUCT_LENGTH']\n",
    "\n",
    "# define a generator function to yield rows of the dataframe\n",
    "def row_generator(df):\n",
    "    for index, row in df.iterrows():\n",
    "        yield row\n",
    "\n",
    "# initialize the tf-idf vectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# define a function to extract features for each row\n",
    "def extract_features(row):\n",
    "    # combine the text columns into a single string\n",
    "    text = ' '.join([str(row[col]) for col in text_cols])\n",
    "    \n",
    "    # compute the tf-idf vectors for the text\n",
    "    tfidf = vectorizer.transform([text])\n",
    "    \n",
    "    # create a numpy array of the numerical features\n",
    "    num_features = np.array([row[col] for col in num_cols])\n",
    "    \n",
    "    # concatenate the tf-idf vectors and numerical features\n",
    "    features = np.concatenate([tfidf.toarray()[0], num_features])\n",
    "    \n",
    "    return features\n",
    "\n",
    "# use parallel processing to extract features for each row\n",
    "num_cores = mp.cpu_count()\n",
    "pool = mp.Pool(num_cores)\n",
    "features = pool.map(extract_features, row_generator(df))\n",
    "pool.close()\n",
    "\n",
    "# convert the list of features to a numpy array\n",
    "X = np.array(features)\n",
    "\n",
    "# extract the target variable\n",
    "y = df['PRODUCT_LENGTH']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ae4844",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
